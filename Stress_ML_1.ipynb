{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "# Modeling tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Cleaned_Final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2022 entries, 0 to 2021\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                                           Non-Null Count  Dtype  \n",
      "---  ------                                                           --------------  -----  \n",
      " 0   Age                                                              2022 non-null   float64\n",
      " 1   Academic_Year                                                    2022 non-null   int64  \n",
      " 2   Current_CGPA                                                     2022 non-null   float64\n",
      " 3   waiver_or_scholarship                                            2022 non-null   int64  \n",
      " 4   PSS1                                                             2022 non-null   int64  \n",
      " 5   PSS2                                                             2022 non-null   int64  \n",
      " 6   PSS3                                                             2022 non-null   int64  \n",
      " 7   PSS4                                                             2022 non-null   int64  \n",
      " 8   PSS5                                                             2022 non-null   int64  \n",
      " 9   PSS6                                                             2022 non-null   int64  \n",
      " 10  PSS7                                                             2022 non-null   int64  \n",
      " 11  PSS8                                                             2022 non-null   int64  \n",
      " 12  PSS9                                                             2022 non-null   int64  \n",
      " 13  PSS10                                                            2022 non-null   int64  \n",
      " 14  Stress_Value                                                     2022 non-null   int64  \n",
      " 15  Stress_Label                                                     2022 non-null   object \n",
      " 16  GAD1                                                             2022 non-null   int64  \n",
      " 17  GAD2                                                             2022 non-null   int64  \n",
      " 18  GAD3                                                             2022 non-null   int64  \n",
      " 19  GAD4                                                             2022 non-null   int64  \n",
      " 20  GAD5                                                             2022 non-null   int64  \n",
      " 21  GAD6                                                             2022 non-null   int64  \n",
      " 22  GAD7                                                             2022 non-null   int64  \n",
      " 23  Anxiety_Value                                                    2022 non-null   int64  \n",
      " 24  Anxiety_Label                                                    2022 non-null   object \n",
      " 25  PHQ1                                                             2022 non-null   int64  \n",
      " 26  PHQ2                                                             2022 non-null   int64  \n",
      " 27  PHQ3                                                             2022 non-null   int64  \n",
      " 28  PHQ4                                                             2022 non-null   int64  \n",
      " 29  PHQ5                                                             2022 non-null   int64  \n",
      " 30  PHQ6                                                             2022 non-null   int64  \n",
      " 31  PHQ7                                                             2022 non-null   int64  \n",
      " 32  PHQ8                                                             2022 non-null   int64  \n",
      " 33  PHQ9                                                             2022 non-null   int64  \n",
      " 34  Depression_Value                                                 2022 non-null   int64  \n",
      " 35  Depression_Label                                                 2022 non-null   object \n",
      " 36  Gender_Female                                                    2022 non-null   bool   \n",
      " 37  Gender_Male                                                      2022 non-null   bool   \n",
      " 38  Gender_Prefer_not_to_say                                         2022 non-null   bool   \n",
      " 39  Department_Biological_Sciences                                   2022 non-null   bool   \n",
      " 40  Department_Business_and_Entrepreneurship_Studies                 2022 non-null   bool   \n",
      " 41  Department_Engineering_-_CS_/_CSE_/_CSC_/_Similar_to_CS          2022 non-null   bool   \n",
      " 42  Department_Engineering_-_Civil_Engineering_/_Similar_to_CE       2022 non-null   bool   \n",
      " 43  Department_Engineering_-_EEE/_ECE_/_Similar_to_EEE               2022 non-null   bool   \n",
      " 44  Department_Engineering_-_Mechanical_Engineering_/_Similar_to_ME  2022 non-null   bool   \n",
      " 45  Department_Engineering_-_Other                                   2022 non-null   bool   \n",
      " 46  Department_Environmental_and_Life_Sciences                       2022 non-null   bool   \n",
      " 47  Department_Law_and_Human_Rights                                  2022 non-null   bool   \n",
      " 48  Department_Liberal_Arts_and_Social_Sciences                      2022 non-null   bool   \n",
      " 49  Department_Other                                                 2022 non-null   bool   \n",
      " 50  Department_Pharmacy_and_Public_Health                            2022 non-null   bool   \n",
      "dtypes: bool(15), float64(2), int64(31), object(3)\n",
      "memory usage: 598.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mild Depression', 'Minimal Depression', 'Moderate Depression',\n",
       "       'Moderately Severe Depression', 'No Depression',\n",
       "       'Severe Depression'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# üß™ Feature Selection & Train-Test Split\n",
    "# ===============================\n",
    "\n",
    "# 1. Drop PHQ items and leakage-related columns\n",
    "phq_cols = [col for col in df.columns if col.startswith(\"PHQ\")]\n",
    "leakage_cols = [\n",
    "    \"Depression_Value\", \"Anxiety_Value\", \"Stress_Value\",\n",
    "    \"Anxiety_Label\", \"Stress_Label\"\n",
    "]\n",
    "columns_to_drop = [col for col in phq_cols + leakage_cols if col in df.columns]\n",
    "\n",
    "# 2. Target before dropping\n",
    "y = df[\"Depression_Label\"]\n",
    "\n",
    "# 3. Drop leakage columns\n",
    "X = df.drop(columns=columns_to_drop + [\"Depression_Label\"])\n",
    "\n",
    "# 4. Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 5. Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 6. Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 7. Class label mapping (for interpretation)\n",
    "label_encoder.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Logistic Regression\n",
      "Cross-validation Accuracy: 0.4872 (+/- 0.0461)\n",
      "Cross-validation F1 Score: 0.4783 (+/- 0.0482)\n",
      "\n",
      "üîç Random Forest\n",
      "Cross-validation Accuracy: 0.5084 (+/- 0.0564)\n",
      "Cross-validation F1 Score: 0.4991 (+/- 0.0587)\n",
      "\n",
      "üîç XGBoost\n",
      "Cross-validation Accuracy: 0.5292 (+/- 0.0541)\n",
      "Cross-validation F1 Score: 0.5244 (+/- 0.0584)\n",
      "\n",
      "üìä Cross-validation Results Summary:\n",
      "                     accuracy_mean  accuracy_std   f1_mean    f1_std\n",
      "Logistic Regression       0.487164      0.023031  0.478324  0.024079\n",
      "Random Forest             0.508437      0.028202  0.499095  0.029344\n",
      "XGBoost                   0.529197      0.027040  0.524432  0.029217\n"
     ]
    }
   ],
   "source": [
    "# Initialize cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_weighted': 'f1_weighted'\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': xgboost.XGBClassifier(random_state=42, use_label_encoder=False)\n",
    "}\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name}\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X_scaled, y_encoded, cv=cv, scoring='accuracy')\n",
    "    cv_f1 = cross_val_score(model, X_scaled, y_encoded, cv=cv, scoring='f1_weighted')\n",
    "    \n",
    "    print(f\"Cross-validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"Cross-validation F1 Score: {cv_f1.mean():.4f} (+/- {cv_f1.std() * 2:.4f})\")\n",
    "    \n",
    "    # Store results\n",
    "    cv_results[name] = {\n",
    "        'accuracy_mean': cv_scores.mean(),\n",
    "        'accuracy_std': cv_scores.std(),\n",
    "        'f1_mean': cv_f1.mean(),\n",
    "        'f1_std': cv_f1.std()\n",
    "    }\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "cv_results_df = pd.DataFrame(cv_results).T\n",
    "print(\"\\nüìä Cross-validation Results Summary:\")\n",
    "print(cv_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class weights:\n",
      "Mild Depression: 0.82\n",
      "Minimal Depression: 3.47\n",
      "Moderate Depression: 0.74\n",
      "Moderately Severe Depression: 0.66\n",
      "No Depression: 7.66\n",
      "Severe Depression: 0.67\n",
      "\n",
      "Normalized class weights:\n",
      "Mild Depression: 0.06\n",
      "Minimal Depression: 0.25\n",
      "Moderate Depression: 0.05\n",
      "Moderately Severe Depression: 0.05\n",
      "No Depression: 0.55\n",
      "Severe Depression: 0.05\n",
      "\n",
      "üîç Logistic Regression (with normalized class weights)\n",
      "Cross-validation Accuracy: 0.4278 (+/- 0.0366)\n",
      "Cross-validation F1 Score: 0.4299 (+/- 0.0438)\n",
      "\n",
      "üîç Random Forest (with normalized class weights)\n",
      "Cross-validation Accuracy: 0.5173 (+/- 0.0699)\n",
      "Cross-validation F1 Score: 0.5088 (+/- 0.0729)\n",
      "\n",
      "üîç XGBoost (with normalized class weights)\n",
      "Cross-validation Accuracy: 0.5292 (+/- 0.0541)\n",
      "Cross-validation F1 Score: 0.5244 (+/- 0.0584)\n",
      "\n",
      "üìä Cross-validation Results with Normalized Class Weights:\n",
      "                     accuracy_mean  accuracy_std   f1_mean    f1_std\n",
      "Logistic Regression       0.427808      0.018282  0.429877  0.021923\n",
      "Random Forest             0.517348      0.034928  0.508833  0.036452\n",
      "XGBoost                   0.529197      0.027040  0.524432  0.029217\n",
      "\n",
      "üìà Performance Comparison (with vs without class weights):\n",
      "                     Without Weights  With Normalized Weights  Improvement\n",
      "Logistic Regression         0.487164                 0.427808    -0.059356\n",
      "Random Forest               0.508437                 0.517348     0.008911\n",
      "XGBoost                     0.529197                 0.529197     0.000000\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ‚öôÔ∏è Handle Class Imbalance with Normalized Class Weights\n",
    "# ===============================\n",
    "\n",
    "# Calculate class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_encoded),\n",
    "    y=y_encoded\n",
    ")\n",
    "\n",
    "# Normalize class weights to sum to 1\n",
    "class_weights_normalized = class_weights / np.sum(class_weights)\n",
    "\n",
    "# Create dictionaries of class weights (both original and normalized)\n",
    "class_weight_dict = dict(zip(np.unique(y_encoded), class_weights))\n",
    "class_weight_dict_normalized = dict(zip(np.unique(y_encoded), class_weights_normalized))\n",
    "\n",
    "print(\"Original class weights:\")\n",
    "for class_label, weight in zip(label_encoder.classes_, class_weights):\n",
    "    print(f\"{class_label}: {weight:.2f}\")\n",
    "\n",
    "print(\"\\nNormalized class weights:\")\n",
    "for class_label, weight in zip(label_encoder.classes_, class_weights_normalized):\n",
    "    print(f\"{class_label}: {weight:.2f}\")\n",
    "\n",
    "# Initialize models with normalized class weights\n",
    "weighted_models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42, \n",
    "        max_iter=1000,\n",
    "        class_weight=class_weight_dict_normalized\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=class_weight_dict_normalized\n",
    "    ),\n",
    "    'XGBoost': xgboost.XGBClassifier(\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        scale_pos_weight=len(y_encoded) / (2 * np.bincount(y_encoded)[1:].sum())  # XGBoost specific weight\n",
    "    )\n",
    "}\n",
    "\n",
    "# Perform cross-validation with weighted models\n",
    "weighted_cv_results = {}\n",
    "for name, model in weighted_models.items():\n",
    "    print(f\"\\nüîç {name} (with normalized class weights)\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X_scaled, y_encoded, cv=cv, scoring='accuracy')\n",
    "    cv_f1 = cross_val_score(model, X_scaled, y_encoded, cv=cv, scoring='f1_weighted')\n",
    "    \n",
    "    print(f\"Cross-validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"Cross-validation F1 Score: {cv_f1.mean():.4f} (+/- {cv_f1.std() * 2:.4f})\")\n",
    "    \n",
    "    # Store results\n",
    "    weighted_cv_results[name] = {\n",
    "        'accuracy_mean': cv_scores.mean(),\n",
    "        'accuracy_std': cv_scores.std(),\n",
    "        'f1_mean': cv_f1.mean(),\n",
    "        'f1_std': cv_f1.std()\n",
    "    }\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "weighted_cv_results_df = pd.DataFrame(weighted_cv_results).T\n",
    "print(\"\\nüìä Cross-validation Results with Normalized Class Weights:\")\n",
    "print(weighted_cv_results_df)\n",
    "\n",
    "# Compare with previous results\n",
    "print(\"\\nüìà Performance Comparison (with vs without class weights):\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Without Weights': cv_results_df['accuracy_mean'],\n",
    "    'With Normalized Weights': weighted_cv_results_df['accuracy_mean'],\n",
    "    'Improvement': weighted_cv_results_df['accuracy_mean'] - cv_results_df['accuracy_mean']\n",
    "})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I drop the linear regression and random forest since they're less performant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Training XGBoost model...\n",
      "Cross-validation Results:\n",
      "Accuracy: 0.5292 (+/- 0.0541)\n",
      "F1 Score: 0.5244 (+/- 0.0584)\n",
      "\n",
      "Class Labels:\n",
      "0: Mild Depression\n",
      "1: Minimal Depression\n",
      "2: Moderate Depression\n",
      "3: Moderately Severe Depression\n",
      "4: No Depression\n",
      "5: Severe Depression\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üöÄ Final XGBoost Model Pipeline\n",
    "# ===============================\n",
    "\n",
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"Prepare the data for modeling\"\"\"\n",
    "    # 1. Drop PHQ items and leakage-related columns\n",
    "    phq_cols = [col for col in df.columns if col.startswith(\"PHQ\")]\n",
    "    leakage_cols = [\n",
    "        \"Depression_Value\", \"Anxiety_Value\", \"Stress_Value\",\n",
    "        \"Anxiety_Label\", \"Stress_Label\"\n",
    "    ]\n",
    "    columns_to_drop = [col for col in phq_cols + leakage_cols if col in df.columns]\n",
    "    \n",
    "    # 2. Get target before dropping\n",
    "    y = df[\"Depression_Label\"]\n",
    "    \n",
    "    # 3. Drop leakage columns\n",
    "    X = df.drop(columns=columns_to_drop + [\"Depression_Label\"])\n",
    "    \n",
    "    # 4. Encode target\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # 5. Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X_scaled, y_encoded, label_encoder\n",
    "\n",
    "def train_xgboost_model(X, y):\n",
    "    \"\"\"Train and evaluate XGBoost model\"\"\"\n",
    "    # Initialize cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Initialize XGBoost model\n",
    "    model = xgb.XGBClassifier(\n",
    "        random_state=RANDOM_SEED,\n",
    "        use_label_encoder=False,\n",
    "        scale_pos_weight=len(y) / (2 * np.bincount(y)[1:].sum())\n",
    "    )\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "    cv_f1 = cross_val_score(model, X, y, cv=cv, scoring='f1_weighted')\n",
    "    \n",
    "    print(\"Cross-validation Results:\")\n",
    "    print(f\"Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"F1 Score: {cv_f1.mean():.4f} (+/- {cv_f1.std() * 2:.4f})\")\n",
    "    \n",
    "    # Train final model on full dataset\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(\"Cleaned_Final.csv\")\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"\\nPreparing data...\")\n",
    "    X_scaled, y_encoded, label_encoder = prepare_data(df)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining XGBoost model...\")\n",
    "    model = train_xgboost_model(X_scaled, y_encoded)\n",
    "    \n",
    "    # Print class labels for reference\n",
    "    print(\"\\nClass Labels:\")\n",
    "    for i, label in enumerate(label_encoder.classes_):\n",
    "        print(f\"{i}: {label}\")\n",
    "    \n",
    "    return model, label_encoder\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, label_encoder = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.32.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (10.1.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (4.25.7)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (16.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
